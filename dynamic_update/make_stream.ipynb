{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f88bcb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include(\"../dyGRASS.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8e0dac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14-element Vector{String}:\n",
       " \"G2\"\n",
       " \"G3\"\n",
       " \"fe_4elt\"\n",
       " \"fe_ocean\"\n",
       " \"fe_sphere\"\n",
       " \"del18\"\n",
       " \"del19\"\n",
       " \"del20\"\n",
       " \"del21\"\n",
       " \"del22\"\n",
       " \"M6\"\n",
       " \"333SP\"\n",
       " \"AS365\"\n",
       " \"NACA\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_folder = \"./dataset\"\n",
    "entries = readdir(dataset_folder; join=true)\n",
    "subfolders = filter(isdir, entries)\n",
    "dataset_names = basename.(subfolders)\n",
    "dataset_names = dataset_names[[3,4,12,13,14,7,8,9,10,11,5,1,2,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8bd2467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting stream_edges folder: dataset/G2/stream_edges\n",
      "Deleting stream_edges folder: dataset/G3/stream_edges\n",
      "Deleting stream_edges folder: dataset/fe_4elt/stream_edges\n",
      "Deleting stream_edges folder: dataset/fe_ocean/stream_edges\n",
      "Deleting stream_edges folder: dataset/fe_sphere/stream_edges\n",
      "Deleting stream_edges folder: dataset/del18/stream_edges\n",
      "Deleting stream_edges folder: dataset/del19/stream_edges\n",
      "Deleting stream_edges folder: dataset/del20/stream_edges\n",
      "Deleting stream_edges folder: dataset/del21/stream_edges\n",
      "Deleting stream_edges folder: dataset/del22/stream_edges\n",
      "Deleting stream_edges folder: dataset/M6/stream_edges\n",
      "Deleting stream_edges folder: dataset/333SP/stream_edges\n",
      "Deleting stream_edges folder: dataset/AS365/stream_edges\n",
      "Deleting stream_edges folder: dataset/NACA/stream_edges\n",
      "Deleted 14 stream_edges folders\n",
      "Reading dataset/G2/ext.mtx with base 1 and type adj and weighted true\n",
      "Reading dataset/G2/del.mtx with base 1 and type adj and weighted false\n",
      "Reading dataset/G3/ext.mtx with base 1 and type adj and weighted true\n",
      "Reading dataset/G3/del.mtx with base 1 and type adj and weighted false\n",
      "Reading dataset/fe_4elt/ext.mtx with base 1 and type adj and weighted true\n",
      "Reading dataset/fe_4elt/del.mtx with base 1 and type adj and weighted false\n",
      "Reading dataset/fe_ocean/ext.mtx with base 1 and type adj and weighted true\n",
      "Reading dataset/fe_ocean/del.mtx with base 1 and type adj and weighted false\n",
      "Reading dataset/fe_sphere/ext.mtx with base 1 and type adj and weighted true\n",
      "Reading dataset/fe_sphere/del.mtx with base 1 and type adj and weighted false\n",
      "Reading dataset/del18/ext.mtx with base 1 and type adj and weighted true\n",
      "Reading dataset/del18/del.mtx with base 1 and type adj and weighted false\n",
      "Reading dataset/del19/ext.mtx with base 1 and type adj and weighted true\n",
      "Reading dataset/del19/del.mtx with base 1 and type adj and weighted false\n",
      "Reading dataset/del20/ext.mtx with base 1 and type adj and weighted true\n",
      "Reading dataset/del20/del.mtx with base 1 and type adj and weighted false\n",
      "Reading dataset/del21/ext.mtx with base 1 and type adj and weighted true\n",
      "Reading dataset/del21/del.mtx with base 1 and type adj and weighted false\n",
      "Reading dataset/del22/ext.mtx with base 1 and type adj and weighted true\n",
      "Reading dataset/del22/del.mtx with base 1 and type adj and weighted false\n",
      "Reading dataset/M6/ext.mtx with base 1 and type adj and weighted true\n",
      "Reading dataset/M6/del.mtx with base 1 and type adj and weighted false\n",
      "Reading dataset/333SP/ext.mtx with base 1 and type adj and weighted true\n",
      "Reading dataset/333SP/del.mtx with base 1 and type adj and weighted false\n",
      "Reading dataset/AS365/ext.mtx with base 1 and type adj and weighted true\n",
      "Reading dataset/AS365/del.mtx with base 1 and type adj and weighted false\n",
      "Reading dataset/NACA/ext.mtx with base 1 and type adj and weighted true\n",
      "Reading dataset/NACA/del.mtx with base 1 and type adj and weighted false\n"
     ]
    }
   ],
   "source": [
    "delete_stream_folders(dataset_names)\n",
    "\n",
    "\n",
    "for name in dataset_names\n",
    "    folder_path = \"dataset\" * \"/\" * name\n",
    "    ext_edges_path = folder_path * \"/ext.mtx\"\n",
    "    del_edges_path = folder_path * \"/del.mtx\"\n",
    "\n",
    "    ext_edges, ext_weight = readMtx(ext_edges_path; base = 1, weighted = true, sort = false)\n",
    "    del_edges,  _ = readMtx(del_edges_path; base = 1, weighted = false, sort = false)\n",
    "\n",
    "    ext_length = size(ext_edges, 1)\n",
    "    del_length = size(del_edges, 1)\n",
    "\n",
    "    incremental_batch_size = cld(ext_length, 10)\n",
    "    decremental_batch_size = cld(del_length, 10)\n",
    "\n",
    "    stream_output_dir = folder_path * \"/stream_edges\"\n",
    "    mkpath(stream_output_dir)\n",
    "\n",
    "    for batch_index in 0:19\n",
    "\n",
    "        if batch_index < 10\n",
    "            # First 10 batches: incremental (0-9)\n",
    "            inc_batch_num = batch_index\n",
    "\n",
    "            start_idx = inc_batch_num * incremental_batch_size + 1\n",
    "            end_idx = min((inc_batch_num + 1) * incremental_batch_size, ext_length)\n",
    "\n",
    "            batch_edges = ext_edges[start_idx:end_idx]\n",
    "            batch_weights = ext_weight[start_idx:end_idx]\n",
    "\n",
    "            filename = stream_output_dir * \"/stream_$(lpad(batch_index, 4, '0'))_incremental.mtx\"\n",
    "            open(filename, \"w\") do file\n",
    "                for i in 1:size(batch_edges, 1)\n",
    "                    println(file, \"$(batch_edges[i][1]) $(batch_edges[i][2]) $(batch_weights[i])\")\n",
    "                end\n",
    "            end\n",
    "\n",
    "        else\n",
    "            # Last 10 batches: decremental (10-19)\n",
    "            dec_batch_num = batch_index - 10\n",
    "\n",
    "            start_idx = dec_batch_num * decremental_batch_size + 1\n",
    "            end_idx = min((dec_batch_num + 1) * decremental_batch_size, del_length)\n",
    "\n",
    "            batch_edges = del_edges[start_idx:end_idx]\n",
    "\n",
    "            filename = stream_output_dir * \"/stream_$(lpad(batch_index, 4, '0'))_decremental.mtx\"\n",
    "            open(filename, \"w\") do file\n",
    "                for i in 1:size(batch_edges, 1)\n",
    "                    println(file, \"$(batch_edges[i][1]) $(batch_edges[i][2])\")\n",
    "                end\n",
    "            end\n",
    "\n",
    "        end\n",
    "\n",
    "\n",
    "\n",
    "    end\n",
    "\n",
    "\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "jbye64x8ydn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "delete_stream_folders (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function delete_stream_folders(dataset_names=nothing)\n",
    "    \"\"\"\n",
    "    Delete all stream_edges folders for specified datasets or all datasets\n",
    "    \n",
    "    Args:\n",
    "        dataset_names: Vector of dataset names to clean, or nothing for all datasets\n",
    "    \"\"\"\n",
    "    \n",
    "    if dataset_names === nothing\n",
    "        # Get all dataset folders if not specified\n",
    "        dataset_folder = \"./dataset\"\n",
    "        entries = readdir(dataset_folder; join=true)\n",
    "        subfolders = filter(isdir, entries)\n",
    "        dataset_names = basename.(subfolders)\n",
    "    end\n",
    "    \n",
    "    deleted_count = 0\n",
    "    \n",
    "    for name in dataset_names\n",
    "        folder_path = \"dataset\" * \"/\" * name\n",
    "        stream_output_dir = folder_path * \"/stream_edges\"\n",
    "        \n",
    "        if isdir(stream_output_dir)\n",
    "            println(\"Deleting stream_edges folder: $stream_output_dir\")\n",
    "            rm(stream_output_dir; recursive=true)\n",
    "            deleted_count += 1\n",
    "        else\n",
    "            println(\"Stream_edges folder does not exist: $stream_output_dir\")\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    println(\"Deleted $deleted_count stream_edges folders\")\n",
    "    return deleted_count\n",
    "end\n",
    "\n",
    "# Example usage:\n",
    "# delete_stream_folders()                    # Delete all stream_edges folders\n",
    "# delete_stream_folders([\"G2\", \"G3\"])       # Delete only specific datasets\n",
    "# delete_stream_folders(dataset_names)      # Delete for current dataset_names list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d455d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3721331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: G2\n",
      "Reading dataset/G2/adj_sparse.mtx with base 0 and type adj and weighted true\n",
      "File saved to dataset/G2/new_adj_sparse.mtx\n",
      "Warning: Treat as lap, but maybe is a self-loop in adjacency matrix.\n",
      "Reading dataset/G2/dense.mtx with base 1 and type lap and weighted true\n",
      "File saved to dataset/G2/new_adj_dense.mtx\n",
      "Processing dataset: G3\n",
      "Reading dataset/G3/adj_sparse.mtx with base 0 and type adj and weighted true\n",
      "File saved to dataset/G3/new_adj_sparse.mtx\n",
      "Warning: Treat as lap, but maybe is a self-loop in adjacency matrix.\n",
      "Reading dataset/G3/dense.mtx with base 1 and type lap and weighted true\n",
      "File saved to dataset/G3/new_adj_dense.mtx\n",
      "Processing dataset: fe_4elt\n",
      "Reading dataset/fe_4elt/adj_sparse.mtx with base 0 and type adj and weighted true\n",
      "File saved to dataset/fe_4elt/new_adj_sparse.mtx\n",
      "Reading dataset/fe_4elt/dense.mtx with base 1 and type adj and weighted false\n",
      "File saved to dataset/fe_4elt/new_adj_dense.mtx\n",
      "Processing dataset: fe_ocean\n",
      "Reading dataset/fe_ocean/adj_sparse.mtx with base 0 and type adj and weighted true\n",
      "File saved to dataset/fe_ocean/new_adj_sparse.mtx\n",
      "Reading dataset/fe_ocean/dense.mtx with base 1 and type adj and weighted false\n",
      "File saved to dataset/fe_ocean/new_adj_dense.mtx\n",
      "Processing dataset: fe_sphere\n",
      "Reading dataset/fe_sphere/adj_sparse.mtx with base 0 and type adj and weighted true\n",
      "File saved to dataset/fe_sphere/new_adj_sparse.mtx\n",
      "Reading dataset/fe_sphere/dense.mtx with base 1 and type adj and weighted false\n",
      "File saved to dataset/fe_sphere/new_adj_dense.mtx\n",
      "Processing dataset: del18\n",
      "Reading dataset/del18/adj_sparse.mtx with base 0 and type adj and weighted true\n",
      "File saved to dataset/del18/new_adj_sparse.mtx\n",
      "Reading dataset/del18/dense.mtx with base 1 and type adj and weighted false\n",
      "File saved to dataset/del18/new_adj_dense.mtx\n",
      "Processing dataset: del19\n",
      "Reading dataset/del19/adj_sparse.mtx with base 0 and type adj and weighted true\n",
      "File saved to dataset/del19/new_adj_sparse.mtx\n",
      "Reading dataset/del19/dense.mtx with base 1 and type adj and weighted false\n",
      "File saved to dataset/del19/new_adj_dense.mtx\n",
      "Processing dataset: del20\n",
      "Reading dataset/del20/adj_sparse.mtx with base 0 and type adj and weighted true\n",
      "File saved to dataset/del20/new_adj_sparse.mtx\n",
      "Reading dataset/del20/dense.mtx with base 1 and type adj and weighted false\n",
      "File saved to dataset/del20/new_adj_dense.mtx\n",
      "Processing dataset: del21\n",
      "Reading dataset/del21/adj_sparse.mtx with base 0 and type adj and weighted true\n",
      "File saved to dataset/del21/new_adj_sparse.mtx\n",
      "Reading dataset/del21/dense.mtx with base 1 and type adj and weighted false\n",
      "File saved to dataset/del21/new_adj_dense.mtx\n",
      "Processing dataset: del22\n",
      "Reading dataset/del22/adj_sparse.mtx with base 0 and type adj and weighted true\n",
      "File saved to dataset/del22/new_adj_sparse.mtx\n",
      "Reading dataset/del22/dense.mtx with base 1 and type adj and weighted false\n",
      "File saved to dataset/del22/new_adj_dense.mtx\n",
      "Processing dataset: M6\n",
      "Reading dataset/M6/adj_sparse.mtx with base 0 and type adj and weighted true\n",
      "File saved to dataset/M6/new_adj_sparse.mtx\n",
      "Reading dataset/M6/dense.mtx with base 1 and type adj and weighted false\n",
      "File saved to dataset/M6/new_adj_dense.mtx\n",
      "Processing dataset: 333SP\n",
      "Reading dataset/333SP/adj_sparse.mtx with base 0 and type adj and weighted true\n",
      "File saved to dataset/333SP/new_adj_sparse.mtx\n",
      "Reading dataset/333SP/dense.mtx with base 1 and type adj and weighted false\n",
      "File saved to dataset/333SP/new_adj_dense.mtx\n",
      "Processing dataset: AS365\n",
      "Reading dataset/AS365/adj_sparse.mtx with base 0 and type adj and weighted true\n",
      "File saved to dataset/AS365/new_adj_sparse.mtx\n",
      "Reading dataset/AS365/dense.mtx with base 1 and type adj and weighted false\n",
      "File saved to dataset/AS365/new_adj_dense.mtx\n",
      "Processing dataset: NACA\n",
      "Reading dataset/NACA/adj_sparse.mtx with base 0 and type adj and weighted true\n",
      "File saved to dataset/NACA/new_adj_sparse.mtx\n",
      "Reading dataset/NACA/dense.mtx with base 1 and type adj and weighted false\n",
      "File saved to dataset/NACA/new_adj_dense.mtx\n"
     ]
    }
   ],
   "source": [
    "for name in dataset_names\n",
    "    println(\"Processing dataset: $name\")\n",
    "    folder_path = \"dataset\" * \"/\" * name\n",
    "\n",
    "    sparse_graph = \"adj_sparse.mtx\"\n",
    "    dense_graph = \"dense.mtx\"\n",
    "\n",
    "    new_sparse_name = \"new_adj_sparse.mtx\"\n",
    "    new_dense_name = \"new_adj_dense.mtx\"\n",
    "\n",
    "    makeSureAdjOneBase(folder_path, sparse_graph, new_sparse_name)\n",
    "    makeSureAdjOneBase(folder_path, dense_graph, new_dense_name)\n",
    "\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35d1ddae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3493, 150)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "incremental_batch_size, decremental_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e4c78ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Any}:\n",
       " [2511, 2687]\n",
       " [167, 229]\n",
       " [119, 185]\n",
       " [88, 203]\n",
       " [142, 176]\n",
       " [197, 199]\n",
       " [199, 317]\n",
       " [30, 42]\n",
       " [23, 326]\n",
       " [72, 383]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = ext_edges[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33aa9953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2511"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1764d0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Any}:\n",
       " [1, 2]\n",
       " [3, 4]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = Any[]\n",
    "push!(a, [1,2])\n",
    "push!(a, [3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c66203c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "minimum(Iterators.flatten(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a96f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
